# 1. Preprocessed data loading

Let's read the preprocessed data in the file *1. Preprocessing and Exploratory Data Analysis (EDA)*.
```{r}
load("Data.RData")
```

Let's convert the target variable *Class* into binary {0,1}.
```{r}
data[,"Class"] <- ifelse(data[,"Class"]=="Good",1,0)
```

# 2. Split data into train and test

Let's split the data randomly into *data_train* (67% or 536 observations) and *data_test* (33% or 264 observations).
```{r}
set.seed(1)
n <- nrow(data)
n_train <- round(0.67*n)
train <- sample(x=1:n,size=n_train,replace=FALSE)
data_train <- data[train,]
data_test <- data[-train,] 
```

# 3. Split train data into K folds for validation

Let's split the *data_train* into K=5 folds of equal size and store them in a *list* with K=5 dataframes.
```{r}
K <- 5
fold_size <- round(n_train/K)
data_train_folds <- list()
indexes <- 0:K*fold_size
for(i in 1:K){
  data_train_folds[[i]] <- data_train[(indexes[i]+1):indexes[i+1],]
}
```

# 4. Define performance metric for validation

This project will use the *AUC* as the performance metric to choose the best parametrization of each *supervised ML* algorithm. Let's define the function *AUC* manually although we could use implemented libraries.
```{r}
AUC <- function(true_labels,predictions) {
  ranks <- rank(predictions)
  n.pos <- sum(true_labels==1)
  n.neg <- length(true_labels)-n.pos
  return((sum(ranks[true_labels==1])-n.pos*(n.pos+1)/2)/(n.pos*n.neg))
}
```

# 5. Save all objects into RData file

```{r}
save(data,data_train,data_test,data_train_folds,AUC,file="Data.RData")
```