# 1. Load the train data K folds and the performance metric function for validation

Let's read the *Data.RData* file created in *3.1. Supervised ML Validation Protocol*.
```{r}
load("Data.RData")
```

Also, assign every feature to its type: *ID*, *nominal* or *categorical*, *numeric*, and *target* or variable to predict.
```{r}
features_id <- c("ID")
features_nominal <- c("Civil_Status","Children","Profession","Buy_A","Buy_B","Buy_C","Buy_D","Buy_E",
                      "Number_Products","Interest","Card","Gender","Habitat_Type")
features_numeric <- c("Age","Seniority","Time_Without_Buying_B","Total_Expenses","Time_Without_Buying")
target <- "Class"
```

# 2. K-Fold Cross-validation for all parametrizations

Let's iterate the train data K folds, training each parametrization of *Random Forest* in the other folds and evaluating the performance metric *AUC* in the actual fold. It will give as 5 estimations of *AUC* in *test* data because we are using out of bag observations (OOB) that have not been used for training the model.

*Note:* You can find more information about this validation process in the section *4.5. Phases of the protocol of model validation* of the file *Guide to Spark Machine Learning for credit scoring.pdf* in my GitHub repository *Guide-to-Spark-Machine-Learning-for-credit-scoring*.

```{r}
# Load the library of the model
library(randomForest)

# Intial time
start.time <- Sys.time()

# List of candidate parametrizations
ntree <- seq(10,100,10)
mtry <- seq(8,18,2)
sampsize <- c(0.5,0.75,1)
nodesize <- c(1,3,5,7,9,11,13,15)
maxnodes <- c(5,10,15,20,25,30)
parametrizations <- expand.grid(ntree,mtry,sampsize,nodesize,maxnodes)
parametrizations_names <- sapply(1:nrow(parametrizations),
                                 function(i){ paste0("ntree=",parametrizations[i,1],"; mtry=",parametrizations[i,2],
                                                     "; sampsize=",parametrizations[i,3],"; nodesize=",parametrizations[i,4],
                                                     "; maxnodes=",parametrizations[i,5])})

# Iterate all candidate parametrizations
results_cv_RF <- data.frame(row.names=parametrizations_names)
for(p in 1:nrow(parametrizations)){
  
  # Iterate all train data folds
  K <- 5
  for(i in 1:K){
    
    # Create the train and test sets for the ith fold
    train_i <- rbind(data_train_folds[[c(1:K)[-i][1]]],data_train_folds[[c(1:K)[-i][2]]],
                     data_train_folds[[c(1:K)[-i][3]]],data_train_folds[[c(1:K)[-i][4]]])
    test_i <- data_train_folds[[i]]
    
    # Convert to factor the binary target for the model
    train_i[,target] <- as.factor(train_i[,target])
    test_i[,target] <- as.factor(test_i[,target])
    
    # Model with parametrization p
    set.seed(1)
    model_RF_i <- randomForest(x=train_i[,c(features_nominal,features_numeric)],
                                  y=train_i[,target],
                                  ntree=parametrizations[p,1] ,
                                  mtry=parametrizations[p,2],
                                  sampsize=round(nrow(train_i)*parametrizations[p,3]),
                                  nodesize=parametrizations[p,4],
                                  maxnodes=parametrizations[p,5],
                                  do.trace=FALSE)
    prediction_RF_i <- predict(model_RF_i,test_i,type="prob")[,2]
    results_cv_RF[p,i] <- AUC(test_i[,target],prediction_RF_i)
  }
}
duration <- Sys.time()-start.time

# Mean the K AUC for each parametrization
results_cv_RF[,K+1] <- apply(results_cv_RF,1,mean)
names(results_cv_RF) <- c(paste0("Fold_",1:K),"Mean_AUC")

# Order the results by highest mean AUC
results_cv_RF <- results_cv_RF[order(-results_cv_RF$Mean_AUC),]
```

Let's see the duration of the validation protocol.
```{r}
duration
```

# 3. Save results into RData and find the best parametrization

The best parametrization is:
- Number of trees (*ntree*): 100
- Number of features to choose randomly to train every tree (*mtry*): 18
- Number of observations to choose randomly to train every tree (*sampsize*): all
- Minimum number of observations in a leaf node (*nodesize*): 1
- Maximum number of nodes in the tree (*maxnodes*): 30
```{r}
save(results_cv_RF,file="Outputs/3.5. Supervised ML Random Forest Results Validation.RData")
results_cv_RF[1,]
```