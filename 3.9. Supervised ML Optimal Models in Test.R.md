# 1. Load the train and test data and the performance metric function for validation

Let's read the *Data.RData* file created in *3.1. Supervised ML Validation Protocol*.
```{r}
load("Data.RData")
```

Also, assign every feature to its type: *ID*, *nominal* or *categorical*, *numeric*, and *target* or variable to predict.
```{r}
features_id <- c("ID")
features_nominal <- c("Civil_Status","Children","Profession","Buy_A","Buy_B","Buy_C","Buy_D","Buy_E",
                      "Number_Products","Interest","Card","Gender","Habitat_Type")
features_nominal_encoded <- paste0(features_nominal,"_encoded")
features_numeric <- c("Age","Seniority","Time_Without_Buying_B","Total_Expenses","Time_Without_Buying")
target <- "Class"
```

# 2. Train each optimal model with all train data

Now, let's select the optimal parametrization of each model found in file *3.8. Supervised ML Results Validation*, and train these optimal models with all *train* data.
```{r}
# KNN
library(VIM)
data_test_copy <- data_test
data_test_copy[,target] <- NA
data_KNN <- rbind(data_test_copy,data_train)
model_KNN <- kNN(data_KNN,variable=target,numFun=mean,k=1,dist_var=c(features_numeric,features_nominal))

# Logstic Regression
model_LR <- glm(Class~.*.,family=binomial,data=data_train[,c(features_numeric,target)])

# Decison Tree
library(rpart)
set.seed(1)
model_DT <- rpart(Class ~ .,
                  data=data_train[,c(target,features_nominal,features_numeric)],
                  method="class",
                  parms=list(split="information"),
                  control=rpart.control(cp=0,
                                        minsplit=9,
                                        minbucket=1,
                                        maxdepth=15))

# Random Forest
library(randomForest)
set.seed(1)
model_RF <- randomForest(x=data_train[,c(features_nominal,features_numeric)],
                         y=as.factor(data_train[,target]),
                         ntree=100 ,
                         mtry=18,
                         sampsize=round(nrow(data_train)*1),
                         nodesize=1,
                         maxnodes=30,
                         do.trace=FALSE)

# XGBoost
library(xgboost)
train_matrix <- data.matrix(data_train[,c(features_numeric,features_nominal_encoded)])
train_xgbDMatrix <- xgb.DMatrix(data=train_matrix,label=data_train[,target])
set.seed(1)
model_XGB <- xgboost(data=train_xgbDMatrix,
                     booster="gbtree",
                     nthread=parallel::detectCores(),                    
                     max_depth=10,
                     nrounds=90,
                     eta=0.16,
                     gamma=0.1,
                     min_child_weight=1,
                     subsample=1,
                     colsample_bytree=0.5,
                     objective="binary:logistic",
                     verbose=F)

# SVM
library(e1071)
model_SVM <- svm(Class~.,
                 type="C-classification",
                 data=data_train[,c(features_nominal,features_numeric,target)],
                 kernel='radial',
                 cost=0.5,
                 probability=TRUE)
```

# 3. Performance of model in test data

Let's define the function *performance* for evaluating the predictive performance of models. It will include the following metrics:

- *AUC* (used in validation)
- *LogLoss* (you can find more information about if in my GitHub file *Handmade_Logistic_Regression.pdf*)
- Percentage of target equal to 1 or *Good* by quartiles (groups of 25%) of predictions (logically a good model that predicts a binary variable will contain more observations with target values equal to 1 in the group of higher predicted values)
```{r}
performance <- function(true_labels,predictions){
  
  # % true positive by quartiles of predictions
  ranks <- rank(predictions,ties.method="first")
  breaks <- quantile(ranks,seq(0,1,0.25))
  predictions_binned <- cut(ranks,breaks=breaks,include.lowest=TRUE)
  true_positive <- sapply(levels(predictions_binned),function(level) mean(true_labels[predictions_binned==level]))
  
  # AUC
  auc <- AUC(true_labels,predictions)
  
  # LogLoss
  predictions <- ifelse(predictions==0,1e-20,predictions)
  logloss <- sum(true_labels*log(predictions)+(1-true_labels)*(1-log(predictions)))/length(true_labels)
  
  return(c(auc,logloss,true_positive))
}
```

Let's evaluate the *performance* function for the *test* data predictions of all optimal models trained with all *train* data.
```{r}
results_test <- matrix(NA,ncol=6,nrow=6,
                       dimnames=list(c("KNN","LR","DT","RF","XGB","SVM"),c("AUC","LogLoss","D1","D2","D3","D4")))

# KNN
prediction_KNN <- model_KNN[model_KNN[,paste0(target,"_imp")]==TRUE,target]
results_test["KNN",] <- performance(data_test[,target],prediction_KNN)

# Logistic Regression
prediction_LR <- predict(model_LR,data_test,type="response")
results_test["LR",] <- performance(data_test[,target],prediction_LR)

# Decision Tree
prediction_DT <- predict(model_DT,data_test,type="prob")[,2]
results_test["DT",] <- performance(data_test[,target],prediction_DT)

# Random Forest
prediction_RF <- predict(model_RF,data_test,type="prob")[,2]
results_test["RF",] <- performance(data_test[,target],prediction_RF)

# XGBoost
test_matrix <- data.matrix(data_test[,c(features_numeric,features_nominal_encoded)])
test_xgbDMatrix <- xgb.DMatrix(data=test_matrix)
prediction_XGB <- predict(model_XGB,test_xgbDMatrix)
results_test["XGB",] <- performance(data_test[,target],prediction_XGB)

# SVM
prediction_SVM <- attr(predict(model_SVM,data_test,probability=TRUE),"probabilities")[,2]
results_test["SVM",] <- performance(data_test[,target],prediction_SVM)
```

Let's see the results of the predictive performance metrics in *test* data of all optimal models ordered by higher *AUC*.
```{r}
library(gridExtra)
pdf("Outputs/3.9. Supervised ML Optimal Models in Test.pdf",width=5,height=5)
results_test <- results_test[order(-results_test[,"AUC"]),]
grid.arrange(tableGrob(round(results_test,4)),top="AUC, LogLoss, and % true positive by quartiles of predictions")
dev.off()
```