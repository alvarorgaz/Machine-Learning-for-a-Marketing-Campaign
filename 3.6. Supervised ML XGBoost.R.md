---
title: "Supervised ML XGBoost"
author: "Álvaro Orgaz Expósito"
---

# 1. Load the train data K folds and the performance metric function for validation

Let's read the *Data.RData* file created in *3.1. Supervised ML Validation Protocol*.
```{r}
load("Data.RData")
```

Also, assign every feature to its type: *ID*, *nominal* or *categorical*, *numeric*, and *target* or variable to predict.
```{r}
features_id <- c("ID")
features_nominal <- paste0(c("Civil_Status","Children","Profession","Buy_A","Buy_B","Buy_C","Buy_D","Buy_E","Number_Products","Interest","Card","Gender","Habitat_Type"),"_encoded")
features_numeric <- c("Age","Seniority","Time_Without_Buying_B","Total_Expenses","Time_Without_Buying")
target <- "Class"
```

# 2. K-Fold Cross-validation for all parametrizations

Let's iterate the train data K folds, training each parametrization of *XGBoost* in the other folds and evaluating the performance metric *AUC* in the actual fold. It will give as 5 estimations of *AUC* in *test* data because we are using out of bag observations (OOB) that have not been used for training the model.

*Note:* You can find more information about this validation process in the section *4.5. Phases of the protocol of model validation* of the file *Guide to Spark Machine Learning for credit scoring.pdf* in my GitHub repository *Guide-to-Spark-Machine-Learning-for-credit-scoring*.

```{r}
# Load the library of the model
library(xgboost)
# Intial time
start.time <- Sys.time()
# List of candidate parametrizations
max_depth <- c(10,15,20)
max_iter <- seq(10,100,10)
step_size <- seq(0.01,0.2,0.05)
gamma <- seq(0,0.10,0.05)
min_child_weight <- c(1,3,5)
subsample <- c(0.5,0.75,1)
colsample_bytree <- c(0.5,0.75,1) 
parametrizations <- expand.grid(max_depth,max_iter,step_size,gamma,min_child_weight,subsample,colsample_bytree)
parametrizations_names <- sapply(1:nrow(parametrizations),
                                 function(i){ paste0("max_depth=",parametrizations[i,1],"; max_iter=",parametrizations[i,2],
                                                     "; step_size=",parametrizations[i,3],"; gamma=",parametrizations[i,4],
                                                     "; min_child_weight=",parametrizations[i,5],"; subsample=",parametrizations[i,6],
                                                     "; colsample_bytree=",parametrizations[i,7])})
# Iterate all candidate parametrizations
results_cv_XGB <- data.frame(row.names=parametrizations_names)
for(p in 1:nrow(parametrizations)){
  # Iterate all train data folds
  K <- 5
  for(i in 1:K){
    # Create the train and test sets for the ith fold
    train_i <- rbind(data_train_folds[[c(1:K)[-i][1]]],data_train_folds[[c(1:K)[-i][2]]],
                     data_train_folds[[c(1:K)[-i][3]]],data_train_folds[[c(1:K)[-i][4]]])
    test_i <- data_train_folds[[i]]
    # Convert the train_i and test_i dataframes into xgb.DMatrix for the model
    test_i_matrix <- data.matrix(test_i[,c(features_numeric,features_nominal)])
    test_i_xgbDMatrix <- xgb.DMatrix(data=test_i_matrix)
    train_i_matrix <- data.matrix(train_i[,c(features_numeric,features_nominal)])
    train_i_xgbDMatrix <- xgb.DMatrix(data=train_i_matrix,label=train_i[,target])
    # Model with parametrization p
    set.seed(1)
    model_XGB_i <- xgboost(data=train_i_xgbDMatrix,
                           booster="gbtree",
                           nthread=parallel::detectCores(),
                           max_depth=parametrizations[p,1],
                           nrounds=parametrizations[p,2],
                           eta=parametrizations[p,3],
                           gamma=parametrizations[p,4],
                           min_child_weight=parametrizations[p,5],
                           subsample=parametrizations[p,6],
                           colsample_bytree=parametrizations[p,7],
                           objective="binary:logistic",
                           verbose=F)
    prediction_XGB_i <- predict(model_XGB_i,test_i_xgbDMatrix)
    results_cv_XGB[p,i] <- auc(roc(test_i[,target],prediction_XGB_i))
  }
}
duration <- Sys.time()-start.time
# Mean the K AUC for each parametrization
results_cv_XGB[,K+1] <- apply(results_cv_XGB,1,mean)
names(results_cv_XGB) <- c(paste0("Fold_",1:K),"Mean_AUC")
# Order the results by highest mean AUC
results_cv_XGB <- results_cv_XGB[order(-results_cv_XGB$Mean_AUC),]
```

Let's see the duration of the validation protocol.
```{r}
duration
```

# 3. Save results into RData and find the best parametrization

The best parametrization is:
- Number of trees (*ntree*): 100
- Number of features to choose randomly to train every tree (*mtry*): 18
- Number of observations to choose randomly to train every tree (*sampsize*): all
- Minimum number of observations in a leaf node (*nodesize*): 1
- Maximum number of nodes in the tree (*maxnodes*): 15
```{r}
save(results_cv_XGB,file="Outputs/3.5. Supervised ML XGBoost Results Validation.RData")
results_cv_XGB[1,]
```