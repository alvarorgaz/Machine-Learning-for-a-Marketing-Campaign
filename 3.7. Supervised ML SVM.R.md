# 1. Load the train data K folds and the performance metric function for validation

Let's read the *Data.RData* file created in *3.1. Supervised ML Validation Protocol*.
```{r}
load("Data.RData")
```

Also, assign every feature to its type: *ID*, *nominal* or *categorical*, *numeric*, and *target* or variable to predict.
```{r}
features_id <- c("ID")
features_nominal <- c("Civil_Status","Children","Profession","Buy_A","Buy_B","Buy_C","Buy_D","Buy_E",
                      "Number_Products","Interest","Card","Gender","Habitat_Type")
features_numeric <- c("Age","Seniority","Time_Without_Buying_B","Total_Expenses","Time_Without_Buying")
target <- "Class"
```

# 2. K-Fold Cross-validation for all parametrizations

Let's iterate the train data K folds, training each parametrization of *SVM* in the other folds and evaluating the performance metric *AUC* in the actual fold. It will give as 5 estimations of *AUC* in *test* data because we are using out of bag observations (OOB) that have not been used for training the model.

*Note:* You can find more information about this validation process in the section *4.5. Phases of the protocol of model validation* of the file *Guide to Spark Machine Learning for credit scoring.pdf* in my GitHub repository *Guide-to-Spark-Machine-Learning-for-credit-scoring*.

```{r}
# Load the library of the model
library(e1071)

# Intial time
start.time <- Sys.time()

# List of candidate parametrizations
costs <- seq(0.1,0.5,0.1)
parametrizations <- expand.grid(c("Linear.Kernel_C","Polynomial.Kernel_Degree.2_C","Polynomial.Kernel_Degree.3_C",
                                  "Radial.Kernel_C"),costs)

# Iterate all candidate parametrizations
K <- 5
results_cv_SVM <- data.frame(row.names=paste0(parametrizations[,1],parametrizations[,2]))
for(c in costs){
  
  # Iterate all train data folds
  for(i in 1:5){
    
    # Create the train and test sets for the ith fold
    train_i <- rbind(data_train_folds[[c(1:K)[-i][1]]],data_train_folds[[c(1:K)[-i][2]]],
                     data_train_folds[[c(1:K)[-i][3]]],data_train_folds[[c(1:K)[-i][4]]])
    test_i <- data_train_folds[[i]]
    
    # Model with kernel linear
    model_SVM_1_i <- svm(Class~.,
                         type="C-classification",
                         data=train_i[,c(features_nominal,features_numeric,target)],
                         kernel='linear',
                         cost=c,
                         probability=TRUE)
    prediction_SVM_1_i <- attr(predict(model_SVM_1_i,test_i,probability=TRUE),"probabilities")[,2]
    results_cv_SVM[paste0("Linear.Kernel_C",c),i] <- AUC(test_i[,target],prediction_SVM_1_i)
    
    # Model with kernel polynomial degree 2
    model_SVM_2_i <- svm(Class~.,
                         type="C-classification",
                         data=train_i[,c(features_nominal,features_numeric,target)],
                         kernel='polynomial',
                         degree=2,
                         cost=c,
                         probability=TRUE)
    prediction_SVM_2_i <- attr(predict(model_SVM_2_i,test_i,probability=TRUE),"probabilities")[,2]
    results_cv_SVM[paste0("Polynomial.Kernel_Degree.2_C",c),i] <- AUC(test_i[,target],prediction_SVM_2_i)
    
    # Model with kernel polynomial degree 3
    model_SVM_3_i <- svm(Class~.,
                         type="C-classification",
                         data=train_i[,c(features_nominal,features_numeric,target)],
                         kernel='polynomial',
                         degree=3,
                         cost=c,
                         probability=TRUE)
    prediction_SVM_3_i <- attr(predict(model_SVM_3_i,test_i,probability=TRUE),"probabilities")[,2]
    results_cv_SVM[paste0("Polynomial.Kernel_Degree.3_C",c),i] <- AUC(test_i[,target],prediction_SVM_3_i)
    
    # Model with kernel radial
    model_SVM_4_i <- svm(Class~.,
                         type="C-classification",
                         data=train_i[,c(features_nominal,features_numeric,target)],
                         kernel='radial',
                         cost=c,
                         probability=TRUE)
    prediction_SVM_4_i <- attr(predict(model_SVM_4_i,test_i,probability=TRUE),"probabilities")[,2]
    results_cv_SVM[paste0("Radial.Kernel_C",c),i] <- AUC(test_i[,target],prediction_SVM_4_i)
  }  
}
duration <- Sys.time()-start.time

# Mean the K AUC for each parametrization
results_cv_SVM[,K+1] <- apply(results_cv_SVM,1,mean)
names(results_cv_SVM) <- c(paste0("Fold_",1:K),"Mean_AUC")

# Order the results by highest mean AUC
results_cv_SVM <- results_cv_SVM[order(-results_cv_SVM$Mean_AUC),]
```

Let's see the duration of the validation protocol.
```{r}
duration
```

# 3. Save results into RData and find the best parametrization

The best parametrization is: all features and K parameter equal to 1.
```{r}
save(results_cv_SVM,file="Outputs/3.7. Supervised ML SVM Results Validation.RData")
results_cv_SVM[1,]
```